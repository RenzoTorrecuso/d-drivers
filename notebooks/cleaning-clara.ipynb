{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('../data/full_data.csv')\n",
    "df_scraped = pd.read_csv('../data/scraping_no_duplicates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of scraped dataframe, similar to df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped.columns = [col.lower() for col in df_scraped.columns]\n",
    "\n",
    "df_scraped.rename({\n",
    "           #'impressions': 'page_impressions',\n",
    "           'page_efahrer_id': 'page_id',\n",
    "           'page_canonical_url': 'url',\n",
    "           'author': 'author_scraped'\n",
    "            }, axis=1, inplace=True)\n",
    "\n",
    "df_scraped.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether the same ids & urls are in both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Page IDs')\n",
    "# Convert Series to sets\n",
    "page_ids_full = set(df_full['page_id'])\n",
    "page_ids_scraped = set(df_scraped['page_id'])\n",
    "\n",
    "# Find the difference between the sets\n",
    "page_ids_difference = page_ids_full.difference(page_ids_scraped)\n",
    "print('Number of IDs that no data was scraped for:', len(page_ids_difference))\n",
    "print(' ')\n",
    "\n",
    "print('Page URLs')\n",
    "# Convert Series to sets\n",
    "page_url_full = set(df_full['url'])\n",
    "page_url_scraped = set(df_scraped['url'])\n",
    "\n",
    "# Find the difference between the sets\n",
    "page_url_difference = page_url_full.difference(page_url_scraped)\n",
    "\n",
    "print('Number URLs that no data was scraped for:',len(page_url_difference))\n",
    "print('Number of URLs in complete dataset:', len(df_full.url.unique()))\n",
    "print('Number of URLs in scraped dataset:', len(df_scraped['url'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">For each ID we have the scraped data but not for every URL. Assumption that the page content is the same for each page ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can merge the dataframe with the scraped content with our full dataset with the performance data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_merge = ['page_id', 'url']\n",
    "df_full_scraped = pd.merge(left=df_full, right=df_scraped, on=col_to_merge, how='left')\n",
    "df_full_scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_scraped['check_merge'] = df_full_scraped['words'] == df_full_scraped['words']\n",
    "\n",
    "print('Number of scraped pages', len(df_scraped.page_id))\n",
    "print('Number of page IDs, that contain scraped data:', len(df_full_scraped[df_full_scraped['abstract'].notnull()]['page_id'].unique()))\n",
    "print('Number of pages that were merged correctly based on word count:', len(df_full_scraped[df_full_scraped['check_merge'] == True]['page_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_scraped['check_merge'] = df_full_scraped['last_update'] == df_full_scraped['publish_date']\n",
    "\n",
    "print('Number of pages that have a different update date compared to the publish date:', len(df_scraped.page_id) - len(df_full_scraped[df_full_scraped['check_merge'] == True]['page_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> Some pages have a different publishing date compared to the scraped update date. This could be as the scraped date is added manually and the published_date from the data set is meta data from the actual day of publishing.</span>\n",
    "<p>In the following the publishing date from the original data set is taken instead of the scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up for the EDA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = df_full_scraped.drop(['url', 'old_index', 'author_scraped', 'words', 'last_update', 'check_merge'], axis=1)\n",
    "df_eda.to_csv('../data/eda.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
